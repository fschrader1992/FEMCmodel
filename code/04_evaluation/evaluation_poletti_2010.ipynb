{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for Simulations of the Experiments by Poletti et al. (2010)\n",
    "\n",
    "This file contains the motion detection stages, including the GMDN set up and creates the resulting plots. The input is provided by the spike time/position files created by running `ms_network_no_m.py`. The parameters for motion detection and properties of the global motion detection can all be varied with a simple rerun of cells, which allows for quick investigation of the resulting behaviour of the model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import cm \n",
    "import cv2\n",
    "import datetime\n",
    "import itertools\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used for error calculation at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter\n",
    "\n",
    "Here all parameters are set ecept $n_D$. Motion detectors are implemented by binning spikes and then comparing different bins in neighboring cells. \n",
    "\n",
    "- `t_full`: simulation time\n",
    "- `t_bin`: interval length for binning in steps (1ms)\n",
    "- `b_vels`: range of bins that get checked (including the upper limit). These are equivalent to velocity ranges for each bin, cf. [additional information](../../additional_info.ipynb)\n",
    "- `n_gmdn`: the number of global motion detection neurons into which the simulated cells get divided in $x$- and $y$-direction, division into simple squares\n",
    "- `npms`: number of neighboring cells that get checked for motion spikes, with the respective delay. For example 2 means that three cells in a row have to spikewith the respective delay fitted to motion velocity and direction.\n",
    "- `gmd_thrs`: global motion detection threshold $N_g$ \n",
    "- `mo_det_thrs`: the minimum number of coincidence events for two intervals, 2 mean that in both cells at the given intervals two spikes must have been detected to spark a motion signal\n",
    "- `md_num`: if `True`, the numbe rof motion detectors that fired during an interval will be contained in the result, otherwise the result for an intervla will be equal to 1, if any detector detected motion (simple presence of motion)\n",
    "- `snums`: numbers of the included simulations\n",
    "- `methods`: `\"md_par\"` means that the GMDNs are activated by parasol cells, `\"md_md\"` means by the respective motion detectors. Both can be simulated simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation time\n",
    "t_full = 1000\n",
    "\n",
    "#time interval length for binning\n",
    "t_bin = 15\n",
    "#range of bins that get checked\n",
    "b_vels = [3, 5]\n",
    "\n",
    "#number of \n",
    "npms = 1\n",
    "\n",
    "#this is the sqrt of the number of gmdns used (so how many in one direction)\n",
    "n_gmdn = np.asarray([1])\n",
    "\n",
    "#number of cells within RF firing accounted to global motion, set in cells\n",
    "gmd_thrs = np.arange(20, 10, -1)\n",
    "\n",
    "#number of coincidence events per bin\n",
    "mo_det_thrs = np.arange(0, 1, 1)\n",
    "\n",
    "# number of simulations\n",
    "snums = np.arange(10, 31)\n",
    "\n",
    "md_num = False\n",
    "\n",
    "methods = [\"md_par\", \"md_md\"]\n",
    "\n",
    "#will contain results, clear here as well\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set up the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get position of parasol neurons for both file sizes\n",
    "gp_file = open('../../data/poletti2010/blocks/1/dot/p_pos_dot_1.data', 'rb')\n",
    "gp_data = np.load(gp_file)\n",
    "gp_file.close()\n",
    "\n",
    "gp_m_file = open('../../data/poletti2010/blocks/1/dot_m/p_pos_dot_m_1.data', 'rb')\n",
    "gp_m_data = np.load(gp_m_file)\n",
    "gp_m_file.close()\n",
    "\n",
    "#get first nodes for both to attribute parasol cells right\n",
    "first_node = 0\n",
    "gid = open('../../data/poletti2010/blocks/1/dot/network/GID_info.txt', 'r+')\n",
    "for l in gid:\n",
    "    if 'parasols' in l.split('\\t')[0].strip():\n",
    "        first_node = int(l.split('\\t')[1].strip())\n",
    "        \n",
    "first_node_m = 0\n",
    "gid_m = open('../../data/poletti2010/blocks/1/dot_m/network/GID_info.txt', 'r+')\n",
    "for l in gid_m:\n",
    "    if 'parasols' in l.split('\\t')[0].strip():\n",
    "        first_node_m = int(l.split('\\t')[1].strip())\n",
    "        \n",
    "f_n = first_node\n",
    "n_pos_n = {}\n",
    "swidth = 60.\n",
    "sheight = 30.\n",
    "for q in gp_data:\n",
    "    for p in q:\n",
    "        n_pos_n[f_n] = (int(p[0]/(swidth/float(n_gmdn))), 0) #(0, 0) \n",
    "        f_n += 1\n",
    "\n",
    "f_m = first_node_m\n",
    "n_pos_m = {}\n",
    "\n",
    "swidth = 120.\n",
    "for q in gp_m_data:\n",
    "    for p in q:\n",
    "        n_pos_m[f_m] = (int(p[0]/(swidth/float(n_gmdn))), int(p[0]/(sheight/float(n_gmdn)))) #(0, 0)\n",
    "        f_m += 1      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of Motion Detection Mechanism\n",
    "\n",
    "This block gets the input form the file and runs the whole motion detection stage for each simulation. In the end it puts together the conditions by putting together the respective simulated blocks (border + dot) for each simulation. Data will be stored in form of \n",
    "\n",
    "`results[(<global motion detection threshold>, <spike number motion detection threshold>, <experiment nr>, <condition nr>, <simulation nr>, <GMDN input method>)]`\n",
    "\n",
    "For the GMDN we assume that in the final stage it has to encompass the whole simulated region, dot and border, as otherwise the dot would not invoke enough cells to spike such that with the same motion applied to both objects a differential motion signal would arise. Therefore the GMDN data from the border region are also applied to the dot simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names of included blocks, border (refernce frame) has to come first for comparison to work.\n",
    "snames = [\"border\", \"border_m\", \"dot\", \"dot_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for thr in gmd_thrs:\n",
    "\n",
    "    gmd_thr = thr\n",
    "\n",
    "    for md_thr in mo_det_thrs:\n",
    "\n",
    "        print('GDMN Nr ' + str(n_gmdn) + ' (' + str(int(len(gp_data)*len(gp_data[0])/(n_gmdn))) + \n",
    "              ' cells) GMDN threshold ' + str(thr) + ' cells, motion threshold ' + str(md_thr) + ' spikes.')\n",
    "\n",
    "        in_data = {}\n",
    "        bin_data = {}\n",
    "        \n",
    "        #iterate through all simulations\n",
    "        for snum in snums:\n",
    "            \n",
    "            snum_name = str(snum)\n",
    "            if snum == 10:\n",
    "                snum_name = \"fem_comp\"\n",
    "\n",
    "            print(\"simulation number \" + str(snum))\n",
    "            \n",
    "            #open all four files and run, then store results in dict\n",
    "            for sname in snames:\n",
    "                in_data[(snum, sname)] = open('../../data/poletti2010/blocks/' + snum_name + '/' + sname +\n",
    "                                              '/network/spikes_parasols_' + sname + '_' +\n",
    "                                              snum_name + '.txt', 'r+')\n",
    "\n",
    "                if sname.count(\"_m\") > 0:\n",
    "                    n_pos = n_pos_m\n",
    "                else:\n",
    "                    n_pos = n_pos_n\n",
    "\n",
    "                pos = []\n",
    "                sp = []\n",
    "\n",
    "                sp_pos = {}\n",
    "                p = 0\n",
    "                \n",
    "                #extract the spike times from file\n",
    "                for line in in_data[(snum, sname)]:\n",
    "                    if len(line.split('[')) > 1:\n",
    "                        p = int(line.split('[')[0])\n",
    "                        spikes = line.split('[')[1]\n",
    "                    if len(line.split(']')) > 0:\n",
    "                        spikes = spikes.split(']')[0]\n",
    "                        \n",
    "                    #convert spike times to bin numbers \n",
    "                    sp_n = []\n",
    "                    for s in spikes.split(' '):\n",
    "                        if len(s.strip()) > 0:\n",
    "                            pos += [p]\n",
    "                            sp += [float(s)]\n",
    "                            sp_n += [int((float(s)-0.01)/t_bin)]\n",
    "                    #add position to \n",
    "                    sp_pos[p] = sp_n                        \n",
    "\n",
    "                in_data[(snum, sname)].close()\n",
    "\n",
    "\n",
    "                #store the number of parasol cells firing for each interval\n",
    "                bins_par_num = np.zeros(shape=(1, 1, int(t_full/t_bin) + 1))\n",
    "                bins_r_num = np.zeros(shape=(1, 1, int(t_full/t_bin) + 1))\n",
    "                bins_l_num = np.zeros(shape=(1, 1, int(t_full/t_bin) + 1))\n",
    "\n",
    "                #iterate through parasols\n",
    "                for key in sp_pos:\n",
    "\n",
    "                    #to check the number of parasol cells spiking within one bin\n",
    "                    did_spike = list(set(sp_pos[key]))\n",
    "                    #get number of parasol cells spiking wihtin one bin\n",
    "                    for d_s in did_spike:\n",
    "                        if sp_pos[key].count(d_s) > md_thr:\n",
    "                            bins_par_num[n_pos[key][0]][n_pos[key][1]][d_s] += 1\n",
    "\n",
    "                    #get the number of motion detectors firing        \n",
    "                    for d_s in did_spike:\n",
    "                        \n",
    "                        #rightward motion\n",
    "                        fs = []\n",
    "                        for npm in range(npms):\n",
    "                            fs += [0]\n",
    "                            #if cell fired at least once during simulaton time\n",
    "                            if key - (npm + 1) in sp_pos:\n",
    "                                #check specific intervals\n",
    "                                for b_vel in range((npm  + 1) * b_vels[0], (npm  + 1) * b_vels[1] + 1):\n",
    "                                    if (sp_pos[key].count(d_s) > md_thr and \n",
    "                                        sp_pos[key - (npm + 1)].count(d_s - b_vel) > md_thr):\n",
    "\n",
    "                                        #set to 1, if \n",
    "                                        fs[npm] = 1\n",
    "\n",
    "                        #leftward motion\n",
    "                        fs_l = []\n",
    "                        for npm in range(npms):\n",
    "                            fs_l += [0]\n",
    "                            if key + (npm + 1) in sp_pos:\n",
    "                                for b_vel in range((npm  + 1) * b_vels[0], (npm + 1) * b_vels[1] + 1):\n",
    "                                    if (sp_pos[key].count(d_s) > md_thr and \n",
    "                                        sp_pos[key + (npm + 1)].count(d_s - b_vel) > md_thr):\n",
    "\n",
    "                                        fs_l[npm] = 1\n",
    "\n",
    "                        #if motion detectors in both directions simultaneously detect a motion signal \n",
    "                        #-> suppress\n",
    "                        if 0 not in fs and 0 in fs_l:\n",
    "                            bins_r_num[n_pos[key][0]][n_pos[key][1]][d_s] += 1\n",
    "\n",
    "                        if 0 not in fs_l and 0 in fs:\n",
    "                            bins_l_num[n_pos[key][0]][n_pos[key][1]][d_s] += 1\n",
    "\n",
    "\n",
    "\n",
    "                '''\n",
    "                #GLOBAL MOTION DETECTION -- SKIPPED\n",
    "                gmdns_par = (bins_par_num < gmd_thr).astype(int)\n",
    "                gmdns_r = (bins_r_num < gmd_thr).astype(int)\n",
    "                gmdns_l = (bins_l_num < gmd_thr).astype(int)     \n",
    "                '''\n",
    "                \n",
    "                #If assuming one GMDN for both objects (>10deg) -> approximation, as few spikes for dot\n",
    "                if sname.count(\"border\") > 0:\n",
    "                    if sname.count(\"_m\") == 0:\n",
    "                        g_b_par = copy.deepcopy((bins_par_num < gmd_thr).astype(int))\n",
    "                        g_b_r = copy.deepcopy((bins_r_num < gmd_thr).astype(int))\n",
    "                        g_b_l = copy.deepcopy((bins_l_num < gmd_thr).astype(int))\n",
    "                        \n",
    "                    else:\n",
    "                        g_b_par_m = copy.deepcopy((bins_par_num < gmd_thr).astype(int))\n",
    "                        g_b_r_m = copy.deepcopy((bins_r_num < gmd_thr).astype(int))\n",
    "                        g_b_l_m = copy.deepcopy((bins_l_num < gmd_thr).astype(int))\n",
    "\n",
    "                if sname.count(\"_m\") > 0:       \n",
    "                    gmdns_par = g_b_par_m\n",
    "                    gmdns_r = g_b_r_m\n",
    "                    gmdns_l = g_b_l_m\n",
    "                    \n",
    "                else:\n",
    "                    gmdns_par = g_b_par\n",
    "                    gmdns_r = g_b_r\n",
    "                    gmdns_l = g_b_l\n",
    "                # end for approximation    \n",
    "                \n",
    "                \n",
    "                #if number of cells spiking in output\n",
    "                if md_num:\n",
    "                    bins_par_on_gmd = bins_par_num  * gmdns_par\n",
    "                    bins_r_on_gmd_par = bins_r_num * gmdns_par\n",
    "                    bins_l_on_gmd_par = bins_l_num * gmdns_par\n",
    "                    bins_r_on_gmd_r = bins_r_num * gmdns_r\n",
    "                    bins_l_on_gmd_l = bins_l_num * gmdns_l\n",
    "                \n",
    "                else:\n",
    "                    bins_r_on_gmd_par = (bins_r_num > 0).astype(int) * gmdns_par\n",
    "                    bins_l_on_gmd_par = (bins_l_num > 0).astype(int) * gmdns_par\n",
    "                    bins_r_on_gmd_r = (bins_r_num > 0).astype(int) * gmdns_r\n",
    "                    bins_l_on_gmd_l = (bins_l_num > 0).astype(int) * gmdns_l\n",
    "\n",
    "                #difference in leftward vs. rightward motion.\n",
    "                bins_lr_on_gmd_par = np.abs(bins_r_on_gmd_par - bins_l_on_gmd_par) \n",
    "                bins_lr_on_gmd_each = np.abs(bins_r_on_gmd_r - bins_l_on_gmd_l)\n",
    "\n",
    "\n",
    "                #with several GMDNs, add data from each for each interval    \n",
    "                bins_lr_on_gmd_par = np.add.reduce(bins_lr_on_gmd_par, 0)    \n",
    "                bins_lr_on_gmd_par = np.add.reduce(bins_lr_on_gmd_par, 0)\n",
    "                bins_lr_on_gmd_each = np.add.reduce(bins_lr_on_gmd_each, 0)    \n",
    "                bins_lr_on_gmd_each = np.add.reduce(bins_lr_on_gmd_each, 0)\n",
    "\n",
    "                \n",
    "                # save data for evaluation\n",
    "                bin_data[(snum, sname, \"md_par\")] = bins_lr_on_gmd_par\n",
    "                bin_data[(snum, sname, \"md_md\")] = bins_lr_on_gmd_each\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # PUT EXPERIMENTS AND CONDITIONS TOGETHER\n",
    "            # snum == 0: FEM compensated simulations\n",
    "            if snum != 0:\n",
    "                for method in methods:\n",
    "\n",
    "                    # results[(exp, cond, snum, method)]\n",
    "\n",
    "                    # EXPERIMENT 1\n",
    "                    results[(thr, md_thr, \"1\", \"1\", snum, method)]  = bin_data[(snum, \"dot\", method)]\n",
    "                    results[(thr, md_thr, \"1\", \"1m\", snum, method)] = bin_data[(snum, \"dot_m\", method)]\n",
    "\n",
    "                    results[(thr, md_thr, \"1\", \"2\", snum, method)]  = bin_data[(10, \"dot\", method)]\n",
    "                    results[(thr, md_thr, \"1\", \"2m\", snum, method)] = bin_data[(10, \"dot_m\", method)]\n",
    "\n",
    "\n",
    "                    # EXPERIMENT 2\n",
    "                    results[(thr, md_thr, \"2\", \"1\", snum, method)]  = bin_data[(snum, \"dot\", method)] - bin_data[(snum, \"border\", method)]\n",
    "                    results[(thr, md_thr, \"2\", \"1m\", snum, method)] = bin_data[(snum, \"dot_m\", method)] - bin_data[(snum, \"border\", method)]\n",
    "\n",
    "                    results[(thr, md_thr, \"2\", \"2\", snum, method)]  = bin_data[(10, \"dot\", method)] - bin_data[(snum, \"border\", method)]\n",
    "                    results[(thr, md_thr, \"2\", \"2m\", snum, method)] = bin_data[(10, \"dot_m\", method)] - bin_data[(snum, \"border\", method)]\n",
    "\n",
    "                    results[(thr, md_thr, \"2\", \"3\", snum, method)]  = bin_data[(10, \"dot\", method)] - bin_data[(10, \"border\", method)]\n",
    "                    results[(thr, md_thr, \"2\", \"3m\", snum, method)] = bin_data[(10, \"dot_m\", method)] - bin_data[(10, \"border\", method)]\n",
    "\n",
    "                    results[(thr, md_thr, \"2\", \"4\", snum, method)]  = bin_data[(snum, \"dot\", method)] - bin_data[(snum, \"border_m\", method)]\n",
    "                    results[(thr, md_thr, \"2\", \"4m\", snum, method)] = bin_data[(snum, \"dot_m\", method)] - bin_data[(snum, \"border_m\", method)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "This part contains the evaluation. In this first step, we simply count the number of intevrals with motion signal and normalize it to the simulation length. If `md_num` is true, the number of all cells that spiked during the simulated time gets plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#the GMDN connections\n",
    "methods = [(\"md_par\", \"Motion, Par\")]\n",
    "methods += [(\"md_md\", \"Motion, MD\")]\n",
    "\n",
    "snums = np.arange(11, 31)\n",
    "\n",
    "for mi, meth in enumerate(methods):\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "    print('VALUES FOR ' + meth[1])\n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    #for motion detection spike thresholds\n",
    "    for md_thr in mo_det_thrs:\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4), sharey=True)\n",
    "        fig.suptitle(r'Values for ' + meth[1] + ' md_thr=' + str(md_thr), weight='bold')\n",
    "\n",
    "        res_effect = [[[] for re in range(2)] for rg in range(len(gmd_thrs))]\n",
    "        res_effect_std = [[[] for re in range(2)] for rg in range(len(gmd_thrs))]\n",
    "\n",
    "        for j, exp in enumerate([\"1\", \"2\"]):\n",
    "\n",
    "            #set specifics for each exp\n",
    "            if exp == \"1\":\n",
    "                conds = [\"1\", \"1m\", \"2\", \"2m\"]\n",
    "            if exp == \"2\":\n",
    "                conds = [\"1\", \"1m\", \"2\", \"2m\", \"3\", \"3m\", \"4\", \"4m\"]\n",
    "            t_st = 0\n",
    "            norm = int((t_full - t_st)/t_bin + 1)\n",
    "            \n",
    "            #iterate through GMDN thresholds\n",
    "            for gtk, thr in enumerate(gmd_thrs):\n",
    "\n",
    "                res_effect[gtk][j] = np.zeros(shape=(len(conds)), dtype=float)\n",
    "                res_effect_std[gtk][j] = np.zeros(shape=(len(conds)), dtype=float)\n",
    "\n",
    "                #iterate through conditions\n",
    "                for q, cond in enumerate(conds):\n",
    "                    \n",
    "                    h_arr = np.zeros(shape=(len(snums)), dtype=float)\n",
    "                    #iterate through simulation numbers\n",
    "                    for s, snum in enumerate(snums):\n",
    "\n",
    "                        #get number of bins which contain 1, then divide by number of all bins\n",
    "\n",
    "                        #first plot max diff (=min) parasols + integral parasols + integral only during t_on\n",
    "                        vals = copy.deepcopy(results[(thr, md_thr, exp, cond, snum, meth[0])][int(t_st/t_bin):int(t_full/t_bin)])\n",
    "\n",
    "                        h_arr[s] = sum(np.abs(vals))/norm\n",
    "                        \n",
    "                    #get data and error\n",
    "                    res_effect[gtk][j][q] = np.mean(h_arr)\n",
    "                    res_effect_std[gtk][j][q] = np.std(h_arr)\n",
    "\n",
    "                #gist_rainbow\n",
    "                axes[j%2].errorbar(conds, res_effect[gtk][j], marker = 'o', linestyle=':', \n",
    "                               color = cm.gist_rainbow(1.-float(gtk)/(float(len(gmd_thrs)) - 1.6)), \n",
    "                               label=str(thr), yerr = res_effect_std[gtk][j])\n",
    "\n",
    "            axes[j%2].set_xlim([-0.5, len(conds) - 0.5])\n",
    "            axes[j%2].set_xticks(conds)\n",
    "            axes[j%2].set_xlabel(r'Condition ')\n",
    "            axes[j%2].set_ylabel('Percentage Motion Response') # [Normalized to Observation Time]')\n",
    "            axes[j%2].grid()\n",
    "            axes[j%2].set_title(\"Experiment \" + exp)\n",
    "\n",
    "            #axes[j%2].set_ylim([0, 1])\n",
    "            box = axes[j%2].get_position()\n",
    "            axes[j%2].set_position([box.x0, box.y0 + box.height * 0.25, box.width, 0.75 * box.height])\n",
    "\n",
    "        axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=False, ncol=9, \n",
    "                       title='Threshold [# Cells]')\n",
    "        #plt.savefig('../results/poletti2010/motion_values_' + meth[0].replace(\" \", \"\") + '_gmd100_bin15_v2_4.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these data choose a threshold $n_D$ for the number of bins with motion detected, above which the trial is valued as \"1\". Apart from this, the code is as in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "methods = []\n",
    "methods += [(\"md_par\", \"Motion\")]\n",
    "\n",
    "snums = np.arange(11, 31)\n",
    "\n",
    "# best fit would be gmd_thr=13, nthr=0., with bins=[3,5]\n",
    "gmd_thr = 15\n",
    "nthrs = [0.23] #np.arange(0.35, 0.55, 0.02)\n",
    "\n",
    "for mi, meth in enumerate(methods):\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "    print('VALUES FOR ' + meth[1])\n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    for md_thr in mo_det_thrs:\n",
    "\n",
    "        #plot integrals only during t_on for different exp, for different methods\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4), sharey=True)\n",
    "        fig.suptitle(r'Values for ' + meth[1] + ' md_thr=' + str(md_thr), weight='bold')\n",
    "\n",
    "        res_effect = [[[] for re in range(2)] for rg in range(len(nthrs))]\n",
    "        res_effect_yerr = [[[] for re in range(2)] for rg in range(len(nthrs))]\n",
    "        res_effect_le = [[[] for re in range(2)] for rg in range(len(nthrs))]\n",
    "        res_effect_ue = [[[] for re in range(2)] for rg in range(len(nthrs))]\n",
    "\n",
    "        for j, exp in enumerate([\"1\", \"2\"]):\n",
    "\n",
    "            #set specifics for each exp\n",
    "            if exp == \"1\":\n",
    "                conds = [\"1\", \"1m\", \"2\", \"2m\"]\n",
    "            if exp == \"2\":\n",
    "                conds = [\"1\", \"1m\", \"2\", \"2m\", \"3\", \"3m\", \"4\", \"4m\"]\n",
    "            t_st = 0\n",
    "            norm = int((t_full - t_st)/t_bin + 1)\n",
    "\n",
    "            for gtk, nthr in enumerate(nthrs):\n",
    "\n",
    "                res_effect[gtk][j] = np.zeros(shape=(len(conds)), dtype=float)\n",
    "                res_effect_yerr[gtk][j] = np.zeros(shape=(len(conds)), dtype=float)\n",
    "                res_effect_le[gtk][j] = np.zeros(shape=(len(conds)), dtype=float)\n",
    "                res_effect_ue[gtk][j] = np.zeros(shape=(len(conds)), dtype=float)\n",
    "\n",
    "                for q, cond in enumerate(conds):\n",
    "                    \n",
    "                    h_arr = np.zeros(shape=(len(snums)), dtype=float)\n",
    "                    for s, snum in enumerate(snums):\n",
    "\n",
    "                        #get number of bins which contains 1, then divide by all number of bin \n",
    "                        vals = copy.deepcopy(results[(gmd_thr, md_thr, exp, cond, snum, meth[0])][int(t_st/t_bin):int(t_full/t_bin)])\n",
    "                        \n",
    "                        if sum(np.abs(vals))/norm >= nthr:\n",
    "                            #print(sum(np.abs(vals))/norm)\n",
    "                            h_arr[s] = 100\n",
    "                        else:            \n",
    "                            h_arr[s] = 0 #sum(hh_arr)/norm #sum(np.abs(vals))/norm\n",
    "                        #'''\n",
    "                        \n",
    "                    # get data and error\n",
    "                    res_effect[gtk][j][q] = mean_confidence_interval(h_arr, confidence=0.95)[0]\n",
    "                    res_effect_le[gtk][j][q] = mean_confidence_interval(h_arr, confidence=0.95)[0] - mean_confidence_interval(h_arr, confidence=0.95)[1]\n",
    "                    res_effect_ue[gtk][j][q] = mean_confidence_interval(h_arr, confidence=0.95)[2] - mean_confidence_interval(h_arr, confidence=0.95)[0]\n",
    "                    #0 #np.std(h_arr) #/norm\n",
    "\n",
    "                print(res_effect[gtk][j])\n",
    "                #gist_rainbow\n",
    "                axes[j%2].errorbar(conds, res_effect[gtk][j], marker = 'o', #linestyle=':', \n",
    "                                   color = cm.gist_rainbow((1.-float(gtk)/(float(len(nthrs)) - 0.4))),\n",
    "                                   capsize=10, label=str(np.round(100.*nthr, 1)), \n",
    "                                   yerr=(res_effect_ue[gtk][j], res_effect_le[gtk][j])\n",
    "                                  )\n",
    "                \n",
    "            bar_plot_arr = res_effect\n",
    "            bar_plot_arr_le = res_effect_le\n",
    "            bar_plot_arr_ue = res_effect_ue\n",
    "\n",
    "            axes[j%2].set_xlim([-0.5, len(conds) - 0.5])\n",
    "            axes[j%2].set_xticks(conds)\n",
    "            axes[j%2].set_xlabel(r'Condition ')\n",
    "            axes[j%2].set_ylabel('Percentage Motion Response') # [Normalized to Observation Time]')\n",
    "            axes[j%2].grid()\n",
    "            axes[j%2].set_title(\"Experiment \" + exp)\n",
    "\n",
    "            axes[j%2].set_ylim([0, 100])\n",
    "            box = axes[j%2].get_position()\n",
    "            axes[j%2].set_position([box.x0, box.y0 + box.height * 0.25, box.width, 0.75 * box.height])\n",
    "\n",
    "        # Put a legend to the right of the current axis\n",
    "        axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=False, ncol=9, \n",
    "                       title='Threshold [%]')\n",
    "        #plt.savefig('../../results/poletti2010/afc_' + meth[0].replace(\" \", \"\") + '_gmd_'+str(gmd_thr)+'_bin15_v2_4.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get values\n",
    "print(bar_plot_arr)\n",
    "print(bar_plot_arr_le)\n",
    "print(bar_plot_arr_ue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_res_1 = np.asarray([1., 12.8, 10., 12., 7., 10., 5., 12.])/13.\n",
    "\n",
    "exp_res_2 = np.asarray([1., 15., 10., 16., 1., 15., 14., 2.])/16.\n",
    "\n",
    "sr_1 = np.append(res_2[0:4], res_1)\n",
    "\n",
    "p_exp_1 = scipy.stats.pearsonr(exp_res_1, sr_1)\n",
    "print(\"EXPERIMENT 1\")\n",
    "print(p_exp_1)\n",
    "\n",
    "p_exp_2 = scipy.stats.pearsonr(exp_res_2, res_2)\n",
    "print(\"EXPERIMENT 2\")\n",
    "print(p_exp_2)\n",
    "\n",
    "sr_all =  np.append(sr_1, res_2)\n",
    "exp_res_all =  np.append(exp_res_1, exp_res_2)\n",
    "\n",
    "p_exp_all = scipy.stats.pearsonr(exp_res_all, sr_all)\n",
    "print(\"BOTH EXPERIMENTS\")\n",
    "print(p_exp_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plots\n",
    "\n",
    "The rest of the file creates bar plots similar to those in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE THE BAR PLOT FOR EXPERIMENT 1\n",
    "\n",
    "#set plot styles\n",
    "pgf_with_rc_fonts = {\"font.family\": \"serif\",\"font.serif\": [],\"font.sans-serif\": []}\n",
    "plt.rcParams.update(pgf_with_rc_fonts)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "res_1 = copy.deepcopy(bar_plot_arr[0][0])\n",
    "res_1_le = copy.deepcopy(bar_plot_arr_le[0][0])\n",
    "res_1_ue = copy.deepcopy(bar_plot_arr_ue[0][0])\n",
    "res_1_m = copy.deepcopy(bar_plot_arr[0][0])\n",
    "res_1_m_le = copy.deepcopy(bar_plot_arr_le[0][0])\n",
    "res_1_m_ue = copy.deepcopy(bar_plot_arr_ue[0][0])\n",
    "\n",
    "\n",
    "res_2 = copy.deepcopy(bar_plot_arr[0][1])\n",
    "res_2_le = copy.deepcopy(bar_plot_arr_le[0][1])\n",
    "res_2_ue = copy.deepcopy(bar_plot_arr_ue[0][1])\n",
    "res_2_m = copy.deepcopy(bar_plot_arr[0][1])\n",
    "res_2_m_le = copy.deepcopy(bar_plot_arr_le[0][1])\n",
    "res_2_m_ue = copy.deepcopy(bar_plot_arr_ue[0][1])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.set_size_inches(2.5,3.5)\n",
    "\n",
    "print(res_2[0:4])\n",
    "print(res_2_m[0:4])\n",
    "index = np.arange(2)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 1.0 #0.7\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = ax[1].bar(index  - 0.02, (res_1[0], res_1[2]), bar_width, alpha=opacity, color='lightgray', linewidth=0, \n",
    "                   capsize=2, yerr=((res_1_le[0], res_1_le[2]), (res_1_ue[0], res_1_ue[2])), error_kw=error_config, label='Dot still')\n",
    "\n",
    "rects2 = ax[1].bar(index + bar_width + 0.02, (res_1[1], res_1[3]), bar_width, alpha=opacity, color='darkgray', linewidth=0,\n",
    "                   capsize=2, yerr=((res_1_le[1], res_1_le[3]), (res_1_ue[1], res_1_ue[3])), error_kw=error_config, label='Dot moving')\n",
    "\n",
    "rects3 = ax[0].bar(index - 0.02, (res_2[0], res_2[2]), bar_width, alpha=opacity, color='lightgray', linewidth=0, \n",
    "                   capsize=2, yerr=((res_2_le[0], res_2_le[2]), (res_2_ue[0], res_2_ue[2])), error_kw=error_config, label='Dot still')\n",
    "\n",
    "rects4 = ax[0].bar(index + bar_width + 0.02, (res_2[1], res_2[3]), bar_width, alpha=opacity, color='darkgray', linewidth=0,\n",
    "                   capsize=2, yerr=((res_2_le[1], res_2_le[3]), (res_2_ue[1], res_2_ue[3])), error_kw=error_config, label='Dot moving')\n",
    "\n",
    "#plot styles\n",
    "ax[0].set_title('Light',fontsize=11)\n",
    "ax[1].set_title('Dark',fontsize=11)\n",
    "ax[0].set_xlim([-0.4,1.8])\n",
    "ax[1].set_xlim([-0.4,1.8])\n",
    "ax[0].set_xticks([])\n",
    "ax[1].set_xticks([-0.02,0.374 ,1.02,1.374])\n",
    "ax[1].set_xticklabels(('1','1m','2','2m'))\n",
    "ax[1].set_xlabel('Condition',fontsize=8)\n",
    "ax[0].tick_params(axis='x',which='both',top='off',bottom='off',labelsize=8)\n",
    "ax[0].tick_params(axis='y',which='both',left='on',right='off',labelsize=8)\n",
    "ax[1].tick_params(axis='x',which='both',top='off',bottom='off',labelsize=8)\n",
    "ax[1].tick_params(axis='y',which='both',left='on',right='off',labelsize=8)\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[0].yaxis.set_ticks_position('left')\n",
    "ax[1].xaxis.set_ticks_position('bottom')\n",
    "ax[1].yaxis.set_ticks_position('left')\n",
    "\n",
    "\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].set_ylim(0,101)\n",
    "ax[0].set_yticks(np.arange(0,101,20))\n",
    "\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].set_ylim(0,101)\n",
    "ax[1].set_yticks(np.arange(0,101,20))\n",
    "\n",
    "ax[0].set_axisbelow(True)\n",
    "ax[0].grid(axis='y',color='lightgray', linestyle=':', linewidth=0.5)\n",
    "ax[1].set_axisbelow(True)\n",
    "ax[1].grid(axis='y',color='lightgray', linestyle=':', linewidth=0.5)\n",
    "art=[]\n",
    "lgd = ax[0].legend(bbox_to_anchor=(0,-.2,1.,.2), loc=\"lower left\",\n",
    "                mode=\"expand\", borderaxespad=0, ncol=2, fontsize=8, frameon=False)\n",
    "art.append(lgd)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../../results/poletti2010/poletti_exp1_all_15ms_results.pdf', additional_artists=art,bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE THE BAR PLOT FOR EXPERIMENT 2\n",
    "\n",
    "fig, ax2 = plt.subplots(1)\n",
    "fig.set_size_inches(3.5,2)\n",
    "\n",
    "index = np.arange(4)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 1. #0.7\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = ax2.bar(index  - 0.02, (res_2[0], res_2[2], res_2[4], res_2[6]), bar_width, alpha=opacity, \n",
    "                 color='lightgray', linewidth=2, capsize=2, edgecolor='k',\n",
    "                 yerr=((res_2_le[0], res_2_le[2], res_2_le[4], res_2_le[6]), \n",
    "                       (res_2_ue[0], res_2_ue[2], res_2_ue[4], res_2_ue[6])), error_kw=error_config, \n",
    "                 label='Dot Still')\n",
    "\n",
    "rects2 = ax2.bar(index + bar_width + 0.02, (res_2[1], res_2[3], res_2[5], res_2[7]), bar_width, alpha=opacity, \n",
    "                 color='darkgray', linewidth=2, capsize=2, edgecolor='k',\n",
    "                 yerr=((res_2_le[1], res_2_le[3], res_2_le[5], res_2_le[7]), \n",
    "                       (res_2_ue[1], res_2_ue[3], res_2_ue[5], res_2_ue[7])), error_kw=error_config, \n",
    "                 label='Dot Moving')\n",
    "\n",
    "rects1[1].set_edgecolor('r')\n",
    "rects1[3].set_edgecolor('r')\n",
    "rects2[0].set_edgecolor('r')\n",
    "rects2[1].set_edgecolor('r')\n",
    "rects2[2].set_edgecolor('r')\n",
    "\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.set_ylabel('% Differential Motion',fontsize=8)\n",
    "ax2.set_xlabel('Condition',fontsize=8)\n",
    "ax2.set_ylim(0,101)\n",
    "ax2.set_yticks(np.arange(0,101,20))\n",
    "ax2.set_xticks([0.0,0.354,1.,1.354,2.,2.354,3.,3.354])\n",
    "ax2.set_xticklabels(('1','1m','2','2m','3','3m','4','4m'))\n",
    "plt.tick_params(axis='x', which='both', top='off', bottom='off', labelsize=8)\n",
    "plt.tick_params(axis='y', which='both', left='on', right='off', labelsize=8)\n",
    "ax2.xaxis.set_ticks_position('bottom')\n",
    "ax2.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax2.set_axisbelow(True)\n",
    "ax2.grid(axis='y', color='lightgray', linestyle=':', linewidth=0.5)\n",
    "art=[]\n",
    "lgd = ax2.legend(bbox_to_anchor=(0,1.02,1.,.2), loc=\"lower left\",\n",
    "                mode=\"expand\", borderaxespad=0, ncol=2, fontsize=8, frameon=False)\n",
    "\n",
    "art.append(lgd)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../../results/poletti2010/poletti_exp2_all_15ms_results.pdf', additional_artists=art,bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}